{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730bc83a-420e-47a0-b94e-8422a2bcd7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Test').getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "squared_rdd = rdd.map(lambda x: x *2)\n",
    "print(squared_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4fe44-6302-47b6-8814-3291dd73abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([\"Hello Spark\", \"Learning RDD\"])\n",
    "words_rdd = rdd.flatMap(lambda line:line.split())\n",
    "print(words_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9ea79-2eba-4b61-bfc6-b916f5fd950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n",
    "filtered_rdd = rdd.filter(lambda x: x % 2 == 0)\n",
    "print(filtered_rdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf73f4-9d52-4886-9c16-abff78413f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 2, 3, 3, 4])\n",
    "distinct_rdd = rdd.distinct()\n",
    "print(distinct_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdff0a-750f-429d-a0d9-ffe457c57db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n",
    "grouped_rdd = rdd.groupBy(lambda x: x % 2)  \n",
    "print({k: list(v) for k, v in grouped_rdd.collect()}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8accbea-b0d6-4533-ab92-11eca5d66816",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = spark.sparkContext.parallelize([1, 2])\n",
    "rdd2 = spark.sparkContext.parallelize([3, 4])\n",
    "combined_rdd = rdd1.union(rdd2)\n",
    "print(combined_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b8958-2df0-4b81-b88c-20bb73778975",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = spark.sparkContext.parallelize([1, 2, 3])\n",
    "rdd2 = spark.sparkContext.parallelize([3, 4, 5])\n",
    "intersection_rdd = rdd1.intersection(rdd2)\n",
    "print(intersection_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac1c56-9bbd-4295-85bb-af4c87b15776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd1 = spark.sparkContext.parallelize([1, 2, 3])\n",
    "rdd2 = spark.sparkContext.parallelize([2, 3, 4])\n",
    "subtracted_rdd = rdd1.subtract(rdd2)\n",
    "print(subtracted_rdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da92ced-8345-4704-bd66-ff5308f8e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = spark.sparkContext.parallelize([1, 2])\n",
    "rdd2 = spark.sparkContext.parallelize([3, 4])\n",
    "cartesian_rdd = rdd1.cartesian(rdd2)\n",
    "print(cartesian_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5367a5f-bf65-440e-9452-99b510389214",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_rdd = spark.sparkContext.parallelize([('A', 1), ('B', 1), ('A', 2)])\n",
    "reduced_rdd = pair_rdd.reduceByKey(lambda a, b: a + b)\n",
    "print(reduced_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321da5cc-0d93-4b74-ae31-86d8b88e3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_rdd = spark.sparkContext.parallelize([('A', 1), ('A', 2), ('B', 1)])\n",
    "grouped_rdd = pair_rdd.groupByKey()\n",
    "print({k: list(v) for k, v in grouped_rdd.collect()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858831cc-0ec6-45f1-ad5f-e7c76b26f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 3, 2, 4])\n",
    "sorted_rdd = rdd.sortBy(lambda x: x, ascending=False)\n",
    "print(sorted_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf929b1-894b-40f5-9089-252e08856aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_rdd = spark.sparkContext.parallelize([('A', 1), ('B', 2), ('A', 3)])\n",
    "sorted_rdd = pair_rdd.sortByKey()\n",
    "print(sorted_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b813a161-533c-4774-998c-b5d6654da1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5], 5) \n",
    "coalesced_rdd = rdd.coalesce(2) \n",
    "print(coalesced_rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002cead7-819b-4097-8ffd-694d87319b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4], 2)\n",
    "repartitioned_rdd = rdd.repartition(4)\n",
    "print(repartitioned_rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9017fca-4aee-4671-9050-31d0d3dc74cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n",
    "sampled_rdd = rdd.sample(True, 0.5, seed=12) \n",
    "print(sampled_rdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b950a0-48e8-4a32-b6cd-80d4c56ca621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B', (2, 4)), ('A', (1, 3))]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = spark.sparkContext.parallelize([('A', 1), ('B', 2)])\n",
    "rdd2 = spark.sparkContext.parallelize([('A', 3), ('B', 4)])\n",
    "joined_rdd = rdd1.join(rdd2)\n",
    "print(joined_rdd.collect()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b91e23fc-99f8-4d9c-b63c-fab89621440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': ([2], [4]), 'A': ([1], [3])}\n"
     ]
    }
   ],
   "source": [
    "rdd1 = spark.sparkContext.parallelize([('A', 1), ('B', 2)])\n",
    "rdd2 = spark.sparkContext.parallelize([('A', 3), ('B', 4)])\n",
    "cogrouped_rdd = rdd1.cogroup(rdd2)\n",
    "print({k: (list(v[0]), list(v[1])) for k, v in cogrouped_rdd.collect()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e0034b8-f1f4-4a87-93a6-56228e4ba835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "dd = spark.sparkContext.parallelize([('A', 1), ('B', 2), ('A', 3)], 2)\n",
    "partitioned_rdd = rdd.partitionBy(3)\n",
    "print(partitioned_rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39abc0c7-6094-427b-b95d-694e3e768bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (0, 2), (1, 3), (0, 4)]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "keyed_rdd = rdd.keyBy(lambda x: x % 2)  \n",
    "print(keyed_rdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e577c796-44db-4634-9560-230e17e05823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "result = rdd.reduce(lambda a, b: a + b)  \n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee1c851d-b7e7-484d-a0e5-af081f04cd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'A': 2, 'B': 1})\n"
     ]
    }
   ],
   "source": [
    "pair_rdd = spark.sparkContext.parallelize([('A', 1), ('B', 1), ('A', 1)])\n",
    "result = pair_rdd.countByKey()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3733884-1873-4270-bdad-08803b9f8a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([5, 4, 3, 2, 1])\n",
    "print(rdd.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e984fbd9-25d9-4fd4-9484-06608b32bd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 3, 'B': 2}\n"
     ]
    }
   ],
   "source": [
    "pair_rdd = spark.sparkContext.parallelize([('A', 1), ('B', 2), ('A', 3)])\n",
    "result = pair_rdd.collectAsMap()\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53209ba2-0b4a-4166-9475-163840d14939",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3])\n",
    "rdd.foreach(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c05b525-ab08-42cf-a06a-ea8f1a6c7465",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3])\n",
    "rdd.foreach(lambda x: print(x))\n",
    "data = rdd.collect()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3a721c5-f0ac-4ffc-be88-e43d901920ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "print(rdd.first())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdbdf549-b2a3-4cea-800d-cb9643664e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "print(rdd.takeSample(False, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8fd7ee3-927c-4eb7-a164-12bcc3f094a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([3, 1, 2, 4])\n",
    "print(rdd.takeOrdered(2))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38e152e8-5b0d-4651-826d-6824d64f7bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([3, 1, 2, 4])\n",
    "print(rdd.top(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be733d5c-7703-464d-adda-bc9d9d6c8af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "print(rdd.reduce(lambda x, y: x + y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2dc6bfca-3015-4014-b1d7-0aa5ce700fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "print(rdd.fold(0, lambda x, y: x + y))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "234fc00e-5d06-4221-874c-f960c3dd9d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "seqOp = (lambda x, y: (x[0] + y, x[1] + 1))   \n",
    "combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))   \n",
    "result = rdd.aggregate((0, 0), seqOp, combOp)\n",
    "average = result[0] / result[1]\n",
    "print(average)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0229bf3-e0c4-400c-80eb-f112a842efec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'A': 2, 'B': 1})\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([('A', 1), ('B', 1), ('A', 2)])\n",
    "print(rdd.countByKey()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bb62bc3-842e-4bf0-a3bf-d2934b8b4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "rdd.saveAsTextFile(\"/D:\\Pyspark\\Rythmos/output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf589e-9e38-40e6-b9a4-d722504d6e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
